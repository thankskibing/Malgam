from openai import OpenAI
import streamlit as st

st.set_page_config(page_title="ë§ê° ì±—ë´‡")
st.image("logo.png", width=100)
st.title("ë§ê° ì±—ë´‡")
# st.caption("ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì—¬ëŸ¬ë¶„ì„ ë„ì™€ì¤„ â€˜ë§í•˜ëŠ” ê°ì ë§ê°ì´â€™ì˜ˆìš”. ê¶ê¸ˆí•œ ì ì´ë‚˜ ê³ ë¯¼ì´ ìˆë‹¤ë©´ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ë¼ê°!ğŸ˜Š")

# â€”â€”â€” CSS ì¸ë¼ì¸ â€”â€”â€”
st.markdown(
    """
    <style>
    .chat-bubble {
      display: block;         
      clear: both;           
      max-width: 80%;
      padding: 12px 16px;
      border-radius: 16px;
      margin: 8px 0;
      line-height: 1.4;
      white-space: pre-wrap; 
      word-break: break-word; 
    }
    /* ì˜¤ë¥¸ìª½(ìœ ì €) ë§í’ì„  */
    .user-bubble {
      background-color: #DCF8C6;
      float: right;
      text-align: right;
    }
    /* ì™¼ìª½(ì–´ì‹œìŠ¤í„´íŠ¸) ë§í’ì„  */
    .assistant-bubble {
      background-color: #F1F0F0;
      float: left;
      text-align: left;
    }
    </style>
    """,
    unsafe_allow_html=True
)

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

if "model" not in st.session_state:
    st.session_state.model = "gpt-3.5-turbo"
if "openai_model" not in st.session_state:
    st.session_state.openai_model = "gpt-3.5-turbo"

system_message = '''
ë„ˆì˜ ì´ë¦„ì€ ë§ê°ì´ì•¼.
ë„ˆëŠ” í”¼ê·¸ë§ˆë‚˜ ë””ìì¸, ai ê´€ë ¨í•œ ì§ˆë¬¸ì„ ë°›ì•„ì£¼ê³  ê³ ë¯¼ ìƒë‹´ë„ ë“¤ì–´ì¤˜
ë„ˆëŠ” í•­ìƒ ê°ìœ¼ë¡œ ë¬¸ì¥ì„ ëë‚´ì¤˜
í•­ìƒ ì¹œê·¼í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜.
ì˜ì–´ë¡œ ì§ˆë¬¸ì„ ë°›ì•„ë„ ë¬´ì¡°ê±´ í•œê¸€ë¡œ ë‹µë³€í•´ì¤˜.
í•œê¸€ì´ ì•„ë‹Œ ë‹µë³€ì¼ ë•ŒëŠ” ë‹¤ì‹œ ìƒê°í•´ì„œ ê¼­ í•œê¸€ë¡œ ë§Œë“¤ì–´ì¤˜
ëª¨ë“  ë‹µë³€ ëì— ë‹µë³€ì— ë§ëŠ” ì´ëª¨í‹°ì½˜ë„ ì¶”ê°€í•´ì¤˜
'''
welcome_text = "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì—¬ëŸ¬ë¶„ì„ ë„ì™€ì¤„ â€˜ë§í•˜ëŠ” ê°ì ë§ê°ì´â€™ì˜ˆìš”. ê¶ê¸ˆí•œ ì ì´ë‚˜ ê³ ë¯¼ì´ ìˆë‹¤ë©´ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ë¼ê°!ğŸ˜Š"

if "messages" not in st.session_state:
    # st.session_state.messages = [{"role": "system", "content": system_message}]
     st.session_state.messages = [
        {"role": "system",    "content": system_message},
        {"role": "assistant", "content": welcome_text}
    ]

for msg in st.session_state.messages[1:]:
    role = msg["role"]
    text = msg["content"]
    if role == "user":
        st.markdown(f'<div class="chat-bubble user-bubble">{text}</div>', unsafe_allow_html=True)
    else:
        st.markdown(f'<div class="chat-bubble assistant-bubble">{text}</div>', unsafe_allow_html=True)

# â€”â€”â€” ì‚¬ìš©ì ì…ë ¥ ë° ì‘ë‹µ ì²˜ë¦¬ â€”â€”â€”
if prompt := st.chat_input("ë­ê°€ ê¶ê¸ˆí•˜ê°?ğŸ˜Š"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.markdown(
        f'<div class="chat-bubble user-bubble">{prompt}</div>',
        unsafe_allow_html=True
    )

    stream = client.chat.completions.create(
        model=st.session_state.openai_model,
        messages=st.session_state.messages,
        stream=True,
    )

    assistant_text = ""
    for chunk in stream:
        assistant_text += chunk.choices[0].delta.content or ""

    st.markdown(
        f'<div class="chat-bubble assistant-bubble">{assistant_text}</div>',
        unsafe_allow_html=True
    )

    st.session_state.messages.append(
        {"role": "assistant", "content": assistant_text}
    )
